import fitz  # PyMuPDF
import pandas as pd


# Function to extract text from a PDF
def extract_text_from_pdf(pdf_path):
    doc = fitz.open(pdf_path)
    all_text = []

    for page in doc:
        text = page.get_text("text")
        all_text.extend(text.split("\n"))  # Store each line separately

    return all_text


# Function to extract structured data dynamically
def extract_and_clean_data(text_lines):
    structured_data = []
    i = 0

    while i < len(text_lines) - 4:  # Ensure there are enough lines to extract
        if text_lines[i].strip() == "Fund" and text_lines[i + 1].strip() == "NAV":
            # Extract next fund data
            fund_name = text_lines[i + 4].strip()
            nav = text_lines[i + 5].strip()
            record_date = text_lines[i + 6].strip()
            distributions = text_lines[i + 7].strip()

            structured_data.append(
                {"Fund": fund_name, "NAV": nav, "Record Date": record_date, "Distributions": distributions})

            i += 8  # Move index forward to next set of data
        else:
            i += 1  # Keep searching if we haven't hit a "Fund" header

    return structured_data


# Function to export structured data to Excel
def export_to_excel(structured_data, output_path="extracted_funds.xlsx"):
    df = pd.DataFrame(structured_data)

    if df.empty:
        print("âŒ No structured data found. Check extracted text formatting.")
    else:
        df.to_excel(output_path, index=False)
        print(f"âœ… Extracted data saved to {output_path}")


# Main function
def main():
    pdf_path = "/Users/josedhernandez/Desktop/fake_capital_gains_final.pdf"  # Replace with actual PDF path

    # Extract raw text
    text_data = extract_text_from_pdf(pdf_path)

    # Extract and clean the structured data
    structured_data = extract_and_clean_data(text_data)

    # Display the cleaned data
    print("\nðŸ“Š Cleaned Extracted Data:\n", pd.DataFrame(structured_data))

    # Export to Excel
    export_to_excel(structured_data)


# Run the program
if __name__ == "__main__":
    main()






import fitz  # PyMuPDF for PDF text extraction
import pandas as pd
import streamlit as st
import streamlit.web.cli as stcli


import os


# Function to extract text from an uploaded PDF file
def extract_text_from_pdf(uploaded_file):
    doc = fitz.open(stream=uploaded_file.read(), filetype="pdf")
    all_text = []

    for page in doc:
        text = page.get_text("text")
        all_text.extend(text.split("\n"))  # Store each line separately

    return all_text


# Function to extract structured data dynamically
def extract_and_clean_data(text_lines, keywords):
    structured_data = []
    i = 0
    keyword_list = [kw.strip() for kw in keywords.split(",")]  # Convert user input into list

    while i < len(text_lines) - len(keyword_list):  # Ensure enough lines for extraction
        if all(text_lines[i + j].strip() == keyword_list[j] for j in range(len(keyword_list))):
            # Extract data from next line(s) assuming values appear below headers
            values = [text_lines[i + len(keyword_list) + j].strip() for j in range(len(keyword_list))]

            if len(values) == len(keyword_list):
                structured_data.append(dict(zip(keyword_list, values)))

            i += len(keyword_list) + len(values)  # Move index forward
        else:
            i += 1  # Continue searching

    return structured_data


# Function to export structured data to Excel
def export_to_excel(structured_data):
    df = pd.DataFrame(structured_data)

    if df.empty:
        return None

    output_path = "extracted_data.xlsx"
    df.to_excel(output_path, index=False)
    return output_path


# Streamlit UI
st.title("ðŸ“„ PDF Data Extractor")

# Upload PDF file
uploaded_file = st.file_uploader("Upload a PDF file", type=["pdf"])

# Text input for user-defined fields
keywords = st.text_input("Enter keywords to extract (comma-separated)", "Fund, NAV, Record Date, Distributions")

if uploaded_file and keywords:
    # Extract text from uploaded PDF
    text_data = extract_text_from_pdf(uploaded_file)

    # Extract structured data based on user input
    structured_data = extract_and_clean_data(text_data, keywords)

    if structured_data:
        # Save extracted data to Excel
        excel_file = export_to_excel(structured_data)

        # Display extracted data in Streamlit
        st.subheader("ðŸ“Š Extracted Data Preview")
        st.dataframe(pd.DataFrame(structured_data))

        # Provide download link for Excel file
        with open(excel_file, "rb") as f:
            st.download_button("ðŸ“¥ Download Extracted Data", f, file_name="extracted_data.xlsx",
                               mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet")

    else:
        st.warning("âŒ No structured data found. Try adjusting the keywords or check the PDF format.")




